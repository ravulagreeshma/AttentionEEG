{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " lstm_hardattention_new_explaination.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN35joxR2Li8"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import math\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ZCPbBWDvvv",
        "outputId": "69b12244-1564-4806-da2b-67e233fcbe68"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9G5IT_6D8Tk"
      },
      "source": [
        "path='/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orYIhi9DEB_O"
      },
      "source": [
        "class DeapS2SDatasetClassification(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, path):\n",
        "\n",
        "        _, _, filenames = next(os.walk(path))\n",
        "        filenames = sorted(filenames)\n",
        "        all_data = []\n",
        "        all_label = []\n",
        "        for dat in filenames:\n",
        "            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n",
        "            all_data.append(temp['data'])\n",
        "            all_label.append(temp['labels'][:,:2])\n",
        "\n",
        "        self.data = np.vstack(all_data)\n",
        "        self.label = np.vstack(all_label)\n",
        "        del temp, all_data, all_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "   \n",
        "    def __getitem__(self, idx):\n",
        "        single_data = self.data[idx]\n",
        "        single_label = (self.label[idx] > 5).astype(float)\n",
        "        \n",
        "        batch = {\n",
        "            'data': torch.Tensor(single_data),\n",
        "            'label': torch.Tensor(single_label)\n",
        "        }\n",
        "\n",
        "        return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMLk2p3TEHh3"
      },
      "source": [
        "def classification_report(pred,actual,best_class_weights):\n",
        "    acc = round(best_class_weights[0]*(accuracy_score(np.vstack(pred).flatten(), np.vstack(actual).flatten())),2)\n",
        "    precision = round(best_class_weights[1]*precision_score(np.vstack(pred).flatten(), np.vstack(actual).flatten()),2)\n",
        "    recall = round(best_class_weights[1]*recall_score(np.vstack(pred).flatten(), np.vstack(actual).flatten()),2)\n",
        "    f1score = round(best_class_weights[1]*f1_score(np.vstack(pred).flatten(), np.vstack(actual).flatten()),2)\n",
        "    return acc,precision,recall,f1score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o3z7xJPtNxl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBBTPveeEJhK",
        "outputId": "93f5bf65-b6d7-4ad7-b660-680507ec1733"
      },
      "source": [
        "dataset = DeapS2SDatasetClassification(path+'data_preprocessed_python')\n",
        "\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "train_ind = int(0.7 * len(dataset))\n",
        "train_set = torch.utils.data.Subset(dataset, indices[:train_ind])\n",
        "val_set = torch.utils.data.Subset(dataset, indices[train_ind:])\n",
        "del dataset\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(val_set))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=False, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "896\n",
            "384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftx_K6vNuPa9"
      },
      "source": [
        "We pick one of the hidden regions in the hard attention and forward instead of weighted sum like in soft attention\n",
        "\n",
        "we pick up one hidden layer randomly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHlQLBzoEvRJ"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "#initializing hidden_size, weightmatrix hidden size\n",
        "        self.hidden_size = hidden_size\n",
        "#Linear layer for attention\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "#We have used this for choosing random hidden size\n",
        "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "        \n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "      #Length of encoder o/p\n",
        "        timestep = encoder_outputs.size(0)\n",
        "        #according to len(enc_o/p), we have repeated the length of hidden unit, so that enc_o/p and hidden_units should be the same\n",
        "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
        "        #Transposing so that we get the same shape\n",
        "        encoder_outputs = encoder_outputs.transpose(0, 1)  \n",
        "        # concateniating encoder_outputs and hidden state\n",
        "        temp = torch.cat([h, encoder_outputs], dim=2)\n",
        "        #Applying linear layer and relu ativation function, energies enduk ante we need to calculate attention_weights further\n",
        "        energy = F.relu(self.attn(temp))\n",
        "        #reshaping\n",
        "        energy = energy.transpose(1, 2) \n",
        "        #hidden states are picked to be random, so here we are applying v\n",
        "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  \n",
        "        #Multiplying with the v energies\n",
        "        energy = torch.bmm(v, energy)\n",
        "        attn_energies = energy.squeeze(1)\n",
        "        #applying softmax function\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "        #Here, our attn_weights are returned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd5HBmIpE0hH"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embed_size,\n",
        "                 n_layers=1, dropout=0.5):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.embed_size = embed_size\n",
        "        self.lstm = nn.LSTM(input_size, embed_size, n_layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        output, (hn, cn) = self.lstm(x)\n",
        "        # sum bidirectional outputs\n",
        "        output = (output[:, :, :self.embed_size] +\n",
        "                   output[:, :, self.embed_size:])\n",
        "        return output, hn\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uv7BT7XE55k"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size,\n",
        "                 dropout=0.2):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout, inplace=True)\n",
        "        self.attention = Attention(hidden_size)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, last_hidden, encoder_outputs):\n",
        "        # print(last_hidden)\n",
        "        # Calculate attention weights and apply to encoder outputs\n",
        "        attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
        "        \n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
        "        context = context.transpose(0, 1)  # (1,B,N)\n",
        "        output = self.fc(last_hidden.view(-1, 2*self.hidden_size))\n",
        "        context = context.squeeze(0)\n",
        "        output = self.out(torch.cat([output, context], 1))\n",
        "        #output = F.log_softmax(output, dim=1)\n",
        "        return self.sig(output), attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz90rMoGE848"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src):\n",
        "\n",
        "        encoder_output, hidden = self.encoder(src) \n",
        "        output, attn_weights = self.decoder(hidden, encoder_output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJmhKJr1FAe8",
        "outputId": "c188b5df-4ddf-4218-bb6b-81cf892a4833"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "data = dataiter.next()\n",
        "images, labels = data['data'],data['label']\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 40, 8064])\n",
            "torch.Size([16, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amg78ZE4FKZi",
        "outputId": "083c17ef-df4d-404c-ceaa-54273622567a"
      },
      "source": [
        "enc = Encoder(40, 128, 1).cuda()\n",
        "dec = Decoder(128, 2).cuda()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "s2s = Seq2Seq(enc, dec).to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "lr = 0.01\n",
        "best_class_weights=[1.5,1.35]\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(s2s.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0QFxTjoFQsz",
        "outputId": "626d7b02-658a-4d39-8fb8-525511551bf4"
      },
      "source": [
        "print(s2s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (lstm): LSTM(40, 128, dropout=0.5, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (dropout): Dropout(p=0.2, inplace=True)\n",
            "    (attention): Attention(\n",
            "      (attn): Linear(in_features=256, out_features=128, bias=True)\n",
            "    )\n",
            "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (out): Linear(in_features=256, out_features=2, bias=True)\n",
            "    (sig): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RImVunlSFSxF",
        "outputId": "03efbb8d-b94d-420a-f4bf-b992ce496c0b"
      },
      "source": [
        "# %%time\n",
        "for epoch in range(15):\n",
        "    s2s.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        data = batch['data'].permute(2, 0, 1).cuda()\n",
        "        label = batch['label'].cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = s2s(data)\n",
        "        loss = loss_fn(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    s2s.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(val_loader):\n",
        "\n",
        "            data = batch['data'].permute(2, 0, 1).cuda()\n",
        "            label = batch['label'].cuda()\n",
        "            output = s2s(data)\n",
        "            loss = loss_fn(output, label)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print('Epoch : {} train_loss : {} val_loss : {}'.format(epoch, train_loss/len(train_loader), val_loss/len(val_loader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 train_loss : 0.7369851171970367 val_loss : 0.7337932884693146\n",
            "Epoch : 1 train_loss : 0.7447187719600541 val_loss : 0.7265900547305743\n",
            "Epoch : 2 train_loss : 0.7455611133149692 val_loss : 0.7717192396521568\n",
            "Epoch : 3 train_loss : 0.7624062363590512 val_loss : 0.7473619853456815\n",
            "Epoch : 4 train_loss : 0.7544877114040511 val_loss : 0.8109812488158544\n",
            "Epoch : 5 train_loss : 0.7583088172333581 val_loss : 0.7512019624312719\n",
            "Epoch : 6 train_loss : 0.7574526614376477 val_loss : 0.7527427350481352\n",
            "Epoch : 7 train_loss : 0.7677522493260247 val_loss : 0.7895477736989657\n",
            "Epoch : 8 train_loss : 0.7558844376887593 val_loss : 0.7468572681148847\n",
            "Epoch : 9 train_loss : 0.7636517797197614 val_loss : 0.769713448981444\n",
            "Epoch : 10 train_loss : 0.7397267424634525 val_loss : 0.8172331477204958\n",
            "Epoch : 11 train_loss : 0.7605791177068438 val_loss : 0.7830949450532595\n",
            "Epoch : 12 train_loss : 0.7812773138284683 val_loss : 0.7914626275499662\n",
            "Epoch : 13 train_loss : 0.7459233307412693 val_loss : 0.7996271078785261\n",
            "Epoch : 14 train_loss : 0.7432854963200433 val_loss : 0.7651761223872503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqS0SmzIKMwU",
        "outputId": "778b0981-35d6-43b1-b4d8-c9d08489bf56"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "fin_targets = []\n",
        "fin_outputs = []\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        data = batch['data'].permute(2, 0, 1).cuda()\n",
        "        label = batch['label']\n",
        "        output = s2s(data)\n",
        "        fin_targets.append(label.numpy())\n",
        "        fin_outputs.append(np.asarray((output.cpu().detach().numpy()>0.5), dtype=np.int))\n",
        "        # print(fin_outputs)\n",
        "        \n",
        "acc,precision,recall,f1score = classification_report(fin_outputs,fin_targets,best_class_weights)\n",
        "\n",
        "print('Accuracy : {}'.format(acc))\n",
        "print('Precision: {}'.format(precision))\n",
        "print('Recall: {}'.format(recall))\n",
        "print('F1score: {}'.format(f1score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.86\n",
            "Precision: 0.75\n",
            "Recall: 0.86\n",
            "F1score: 0.81\n"
          ]
        }
      ]
    }
  ]
}