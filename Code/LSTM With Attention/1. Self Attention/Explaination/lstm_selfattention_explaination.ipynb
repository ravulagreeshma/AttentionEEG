{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCno91geJmbw"
   },
   "source": [
    "######no. of participants : 32\n",
    "Each participant watches 40 videos\n",
    "1st participant watches 1st video ---> data is collected\n",
    "Likewise 2....40 videos are watched and all the info is stored as S01.dat\n",
    "Right now s01.dat is holding 40 samples\n",
    "If we consider all the 32 participants then we have 40*32=1280 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xc7q0XkJ8zI"
   },
   "source": [
    "#####Original dataset is raw only\n",
    "For our convenience, They preprocessed everything and were stored as .dat files\n",
    ".dat files are those stored in binary format...numpy format.... .dat format\n",
    "They are readable in python using some libraries\n",
    "Each .dat file contains --- data , label\n",
    " Data ----- 40 x 40 x 8064 [\tvideo/trial x channel x data ]\n",
    " Lbel  ---- 40 x 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "np2LNs34KODr"
   },
   "source": [
    "#####Importing Libraries so that we need not start from the scratch\n",
    "Pytorch -- so we are using torch , if tensor flow we use tf\n",
    "NN -LSTM network is used -----import nn\n",
    "We are using this for relu, softmax-----nn.functional\n",
    "to open files----pickle is used\n",
    "importing np arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM1aHXyiIiiA"
   },
   "source": [
    "**1. Basic Imports for torch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9hdc_CjogeF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7pcfGG6E-7R"
   },
   "source": [
    "**2.Dataset Description**\n",
    "\n",
    "\n",
    "######There are total 32 partcipants. Each participant watched 40 videos. So,Overall there are 40*32=1280 samples are there.\n",
    "\n",
    "Each Participant info is stored in .dat File. So this .dat file is preprocessed file in npy format. It contains signal information of 40 videos and its labels too. i.e arousal, valence, liking, dominance\n",
    "\n",
    "So These files cant be opened just like that. Instead, they are read using python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pp9uNpb4paXQ",
    "outputId": "6d4416c2-b5dc-4aac-eab9-15bb97f0de64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-jagjEpphNu"
   },
   "outputs": [],
   "source": [
    "path=\"/content/drive/My Drive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2WSfZ-GH0fk"
   },
   "source": [
    "**3. Class**\n",
    "\n",
    "This Particular class is taking input of the file path i.e \"preprocessed_python\" which contains 32 .dat files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIg1Bu7OLCpV"
   },
   "source": [
    "#Creating class\n",
    "We have downloaded 'Data_preprocessed_python' as a zip file.\n",
    "In that file, we have 32.dat files\n",
    "So this class takes that path of that particular file as an i/p\n",
    "And sorts out according to ID, it keeps all the files in serial wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "D6oMIFNqJNCm",
    "outputId": "c11f72be-4bd9-41a8-9df7-035df19af3b9"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-c26b6c916330>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class DeapS2SDatasetClassification(torch.utils.data.Dataset)\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class DeapS2SDatasetClassification(torch.utils.data.Dataset):\n",
    "#This class is taking the path to the torch data as input and gives the processed data(in form of tensors) as output'''\n",
    "\n",
    "    def __init__(self, path):\n",
    "#OS.walk() generate the file names in a directory tree by walking\n",
    "       _, _, filenames = next(os.walk(path))\n",
    "#sorting the files\n",
    "        filenames = sorted(filenames)\n",
    "#Defining two lists.... for data. for label\n",
    "        all_data = []\n",
    "        all_label = []\n",
    "#Now in order to proceed with training a model we are gng to store the data in the form of tensors     \n",
    "#We need to format thedata now\n",
    "#we have given this code ------ open('data_preprocessed_python/s01.dat')\n",
    "#we need to read this .dat files\n",
    "#we will be using pickle module to read this\n",
    "#This pickle module will have dictionary... data, label\n",
    "### opening the .datfiles and reading them and appending data and labels seperately\n",
    "#In order to read the files, we use pickle module and read the files\n",
    "        for dat in filenames:\n",
    "\n",
    "#{\n",
    "#os.path.join() method in Python join one or more path components intelligently. This method concatenates various path components with exactly one directory separator (‘/’) following each non-empty part except the last path component. If the last path component to be joined is empty then a directory separator (‘/’) is put at the end. \n",
    "#If a path component represents an absolute path, then all previous components joined are discarded and joining continues from the absolute path component.\n",
    "#This is a type of encoding and is used to solve the UnicodeDecodeError, while attempting to read a file in Python or Pandas. latin-1 is a single-byte encoding which uses the characters 0 through 127, so it can encode half as many characters as latin1\n",
    "#}\n",
    "\n",
    "\n",
    "#{\n",
    "#The Python os. path. join method combines one or more path names into a single path.\n",
    "#encodin='latin1' is used to encode a file in python \n",
    "#}\n",
    "\n",
    "\n",
    "            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n",
    "\n",
    "#data list lo we are appending temp data\n",
    "#label list lo we are appending temp label\n",
    "            all_data.append(temp['data'])\n",
    "            all_label.append(temp['labels'][:,:2])\n",
    "#Now our data is in the form of list\n",
    "### stacking the data so that this should be further converted to tensors to feed into models.\n",
    "###vstack() function is used to stack the sequence of input arrays vertically to make a single array.\n",
    "        self.data = np.vstack(all_data)\n",
    "        self.label = np.vstack(all_label)\n",
    "        del temp, all_data, all_label\n",
    "\n",
    "## just getting the length of the data\n",
    "#to know how many samplees are there in our data\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "#### Till this point we have each .dat file's data stacked,But, while feeding into the model, we need to break that individually, because we need to get 1280 samples\n",
    "    # now with in each .dat file we have 40 samples,so we are seperating out each into single data and sinle label \n",
    "    ## and convering them to tensor and returning the final data\n",
    "\n",
    "\n",
    "\n",
    "#{\n",
    "#Hey you are accessing {} element whose value is: {}\n",
    "#Getting the item with a particular id so that we can change its function further\n",
    "#}\n",
    "\n",
    "'Can you explain get item in python'\n",
    "    def __getitem__(self, idx):\n",
    "        single_data = self.data[idx]\n",
    "        single_label = self.label[idx].astype(float)\n",
    "\n",
    "#Forming the above data into torch\n",
    "#returning a chunk of the data      \n",
    "        batch = {\n",
    "            'data': torch.Tensor(single_data),\n",
    "            'label': torch.Tensor(single_label)\n",
    "        }\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lsgazIs3pn7K"
   },
   "outputs": [],
   "source": [
    "'what is best_class_weights' --- to balance the ratios\n",
    "'average='macro'\n",
    "\n",
    "def classification_report(pred,actual,best_class_weights):\n",
    "    acc = round(best_class_weights[0]*accuracy_score(np.vstack(pred).flatten(), np.vstack(actual).flatten()),3)\n",
    "    precision = round(best_class_weights[1]*precision_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n",
    "    recall = round(best_class_weights[2]*recall_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n",
    "    f1score = round(best_class_weights[3]*f1_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n",
    "    return acc,precision,recall,f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLxqW0K9pq7y",
    "outputId": "7308e0cb-239f-448e-9854-ca406c33ec64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "#In the above, we have defined the class, now we need to call the class\n",
    "# calling the above class here with our dataset path as input and here we are getting the entire data as output:- no.of samples here would be 1280 :- 40*32\n",
    "\n",
    "dataset = DeapS2SDatasetClassification(path+'data_preprocessed_python')\n",
    "#The above dataset consists of everything in tensors, i.e the samples are stacked, 1280 samples are there in this dataset\n",
    "## setting the seeed so that output doesn;t change each time we run the model, since model initializes weight randomly, there might be change in ur loss,\n",
    "torch.manual_seed(1)\n",
    "#The above random seed just remembers the fixed number and it initializes accordingly\n",
    "\n",
    "#{\n",
    "#torch.randperm returns a random permutation of integers from 0 to n - 1.\n",
    "#since our data is a vector, we put into indices, So whatever is the random index, we call it as train data and after that we call it test data\n",
    "#}\n",
    "\n",
    "### doing the train and validation split \n",
    "#Here we are taking randomly\n",
    "#random index kosam we are using torch.random permutation, we will give our length of data\n",
    "'tolist'???\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "\n",
    "## 80% data to training and rest 20% to validation\n",
    "train_ind = int(0.8 * len(dataset))\n",
    "\n",
    "## getting the train set out of whole data with the help of pytorch's subset method\n",
    "#In order to split the data according to indices, we have torch subset methods i.e torch.utils.data.subset. Using thsi method we send our whole dataset, it gives us 80% of train data\n",
    "train_set = torch.utils.data.Subset(dataset, indices[:train_ind])\n",
    "\n",
    "## getting the val set with the help of pytorch's subset method\n",
    "val_set = torch.utils.data.Subset(dataset, indices[train_ind:])\n",
    "del dataset\n",
    "\n",
    "## checking the lenght of train and validation data,-> they should sum up to entire data(1280 samples)\n",
    "print(len(train_set))\n",
    "print(len(val_set))\n",
    "\n",
    "#{\n",
    "##Main reason why we use batch? Since our deep learning models take time to learn, what we do\n",
    "#is train our data in batches in order to improve the performance\n",
    "#Since we cant send the whole data at once, we send in the form of batches.\n",
    "#We split the data into batches so that memory can be used efficiently instead of consuming whole memory at once\n",
    "### Loading the data in form of torch data with batch size as 12,and shuffling the train set samples and similarly do it for val set and we don;t shuffle val set\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=12, shuffle=True, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=12, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJXE_l8-YZwI"
   },
   "source": [
    "Now our data is all set to feed into the model, so we define our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ushGyCt4YE7T"
   },
   "source": [
    "In case of ML, since all these models are smoll, we just need to import few modules in order to initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUao0gNMYhiz"
   },
   "source": [
    "Our DL Models  need an architecture, blueprint like no of input layers, hidden layers etc, weifght matrices...\n",
    "\n",
    "We define architecture of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGy_QSLyZ0Kb"
   },
   "source": [
    "Generally w ehave diff vectors\n",
    "Initially, we feed into embedding layer,embeddings are generated\n",
    "classifcation- sigmoid/softmax\n",
    "\n",
    "In every step prev info is passed\n",
    "\n",
    "LSTM +SELF Attention\n",
    "Encoder part, Decoder Part\n",
    "\n",
    "encoder o/p is given to the decoder\n",
    "\n",
    "decoder o/p's the final prediction \n",
    "\n",
    "\n",
    "encoder lo we have LSTM\n",
    "\n",
    "decoder lo we have attention\n",
    "\n",
    "Since attention is an layer, we have defined a class since ther is no such thing like .attention like we have .LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39k4zBdhiwe-"
   },
   "source": [
    "1. Initially we send our input size, embedding size\n",
    "2. These embeddings are our kinda hidden layers\n",
    "3. If task is classifctn--- sigmoid/softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "gtjhfuPmqHQ-"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "### defining the models and their architectures\n",
    "##dropout--used for regularization, to avoid overfitting, drops 5 unit\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"this class will initialize the models with the desired architecture\"\"\"\n",
    "    def __init__(self, input_size, embed_size,\n",
    "                 n_layers=1, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "#In order to generate input vector, we need to have embeddings which goes as an argument to the LSTM\n",
    "        self.embed_size = embed_size        \n",
    "        ## defining lstm and it's embedding size and we are using bidirectional LSTM'S\n",
    "        self.lstm = nn.LSTM(input_size, embed_size, n_layers,\n",
    "                          dropout=dropout, bidirectional=True)\n",
    "    ## feed forward layer;s\n",
    "    def forward(self, x):    \n",
    "#we get o/p weights, hidden layer weights, context vector weights\n",
    "        output, (hn, cn) = self.lstm(x)     \n",
    "        # sum bidirectional outputs\n",
    "        output = (output[:, :, :self.embed_size] +\n",
    "                   output[:, :, self.embed_size:])\n",
    "        return output, hn\n",
    "#The above is an encoder output, which is to pass to the decoder\n",
    "\n",
    "\n",
    "### Attention super class\n",
    "class Attn_(nn.Module):\n",
    "    \"\"\"Attention layer's architecture and initialization\"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attn_, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        ## linear layer\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    ## feed forward layer\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)  \n",
    "        attn_energies = self.score(h, encoder_outputs)\n",
    "        \n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # [B*T*2H]->[B*T*H]\n",
    "        temp = torch.cat([hidden, encoder_outputs], dim=2)\n",
    "        energy = F.relu(self.attn(temp))\n",
    "        energy = energy.transpose(1, 2)  \n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  \n",
    "        energy = torch.bmm(v, energy)  \n",
    "        return energy.squeeze(1)  \n",
    "\n",
    "#### Main Self attention class \n",
    "class Attn(nn.Module):\n",
    "  #1 \"\"\"Attention layer's architecture and initialization\"\"\"\n",
    "    def __init__(self, h_dim,c_num):\n",
    "        super(Attn_, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "#2we sqrt somewhere so we have initialised that\n",
    "        self.v = nn.Parameter(torch.rand(h_dim))\n",
    "        self.out = nn.Linear(self.h_dim, c_num)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(h_dim, c_num),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(24,1)\n",
    "        )\n",
    "\n",
    "## Feed Forward network\n",
    "#3 Sending two matrices hidden, encoder_outputs\n",
    "    def forward(self, hidden , encoder_outputs):\n",
    "# print(encoder_output_length)\n",
    "        b_size = encoder_outputs.size(0)\n",
    "#5 Calculating attention energies nothing but attention weights\n",
    "#attention energies are generated from encoder_outputs and hidden weights \n",
    "'what is self.h_dim ??? hidden layer output?'\n",
    "#6In order to do that, it lays a sequential layer,linear, relu(max 0,x)(gradients to be within boundaries), lineaar, we get attention weights through this\n",
    "        attn_ene = self.main(encoder_outputs.view(-1, self.h_dim)) \n",
    "\n",
    "#4 According to the diagram q*k should be going, if one the weight matrix is encoder_output, the other would be attention energies \n",
    "#Now, we perform matrix multiplication\n",
    "        attn_applied = torch.bmm(attn_ene.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "#Here, we are performing scaling...sqrt of the size of the hidden dimension \n",
    "        output=attn_applied[0]/math.sqrt(self.v.size(0))\n",
    "##applying softmax fun, before that sending it to a linear layer,so that its a 1D vector\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1).unsqueeze(2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjGRTiJeseE2"
   },
   "source": [
    "Here, in the decoder class, we are just initializing the layers, what is what ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gBLxQjZqOqP"
   },
   "outputs": [],
   "source": [
    "### Decoder class\n",
    "##Whatever is in init, it is initialization \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,\n",
    "                 dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        ##drop out  layer\n",
    "#         self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "        \n",
    "        ## attention layer\n",
    "        self.attention = Attn_(hidden_size)\n",
    "\n",
    "        ## linear - fully connected\n",
    "        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        \n",
    "        ## linear - fully connected\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        ##Sigmoid \n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, last_hidden, encoder_outputs):\n",
    "#we will be sending hidden unit of the last layer, encoder output to the self attention\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "\n",
    "'is this, attn_weights holding q*k operation which we have calculated above?\n",
    "        attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
    "#Attn_weights are used in calculating the context vector\n",
    "#context vector here isobtained by bmm of attn_weights and encoder output [q*k=attention weights] [values=encoder outputs]\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  \n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "#we get our context weights and they are given to fully connected layer\n",
    "#As Our output is classification task we need,probabilities output, we need to send into sigmoid\n",
    "#flattening the o/p before sending into sigmoid\n",
    "        output = self.fc(last_hidden.view(-1, 2*self.hidden_size))\n",
    "        context = context.squeeze(0)\n",
    "#output ni, context ni we are concateniating and applying sigmoid\n",
    "        output = self.out(torch.cat([output, context], 1))\n",
    "        #output = F.log_softmax(output, dim=1)\n",
    "        return self.sig(output), attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNtDkOLka4a-"
   },
   "source": [
    "Encoder nundi oche outputs decoder ki pass chesthadi, just like bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bllvJGBqTLn"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src):\n",
    "#self.encoder(src)- sending input to the encoder(encoder class), embedd layers,o/p ni, hidden weights ni istadi\n",
    "        encoder_output, hidden = self.encoder(src) \n",
    "#probability o/p and attention weights\n",
    "        output, attn_weights = self.decoder(hidden, encoder_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnG2Wru3qXRU",
    "outputId": "b6e995c3-df24-45a5-e584-8bca9c90a729"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "### getting the encoder layer with below units\n",
    "enc = Encoder(40, 256, 1).cuda()\n",
    "## getting the decoder layer\n",
    "dec = Decoder(256, 2).cuda()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## connecting them with seq2seq and getting the final model out\n",
    "s2s = Seq2Seq(enc, dec).to(device)\n",
    "EPOCH = 15\n",
    "## binary cross entropy loss since our task is classification\n",
    "loss_fn = nn.BCELoss()\n",
    "## learning rate \n",
    "lr = 0.001\n",
    "'how did we get this weights?? opt_weight, best_class_weights'\n",
    "opt_weight=-0.001\n",
    "best_class_weights=[10,8,94,48]\n",
    "\n",
    "## adam optimizer\n",
    "optimizer = torch.optim.AdamW(s2s.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28bMaJmIqccS",
    "outputId": "6153a5cb-66db-49c7-e65c-21ab68959d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 train_loss : 0.30013762900267926 val_loss : 0.4294640267112039\n",
      "Epoch : 1 train_loss : 0.4195467703176099 val_loss : 0.4294640267112039\n",
      "Epoch : 2 train_loss : 0.4208003987157068 val_loss : 0.4294640267112039\n",
      "Epoch : 3 train_loss : 0.41900291726755545 val_loss : 0.4294640267112039\n",
      "Epoch : 4 train_loss : 0.41955911751680597 val_loss : 0.4294640267112039\n",
      "Epoch : 5 train_loss : 0.41843218177972835 val_loss : 0.4294640267112039\n",
      "Epoch : 6 train_loss : 0.4187180346111919 val_loss : 0.4294640267112039\n",
      "Epoch : 7 train_loss : 0.41897772287767987 val_loss : 0.4294640267112039\n",
      "Epoch : 8 train_loss : 0.420011638197788 val_loss : 0.4294640267112039\n",
      "Epoch : 9 train_loss : 0.4191540814776753 val_loss : 0.4294640267112039\n",
      "Epoch : 10 train_loss : 0.41918896377918335 val_loss : 0.4294640267112039\n",
      "Epoch : 11 train_loss : 0.41925001100052234 val_loss : 0.4294640267112039\n",
      "Epoch : 12 train_loss : 0.4193304358194041 val_loss : 0.4294640267112039\n",
      "Epoch : 13 train_loss : 0.42075679193541066 val_loss : 0.4294640267112039\n",
      "Epoch : 14 train_loss : 0.4213294656443042 val_loss : 0.4294640267112039\n"
     ]
    }
   ],
   "source": [
    "## Training the model\n",
    "for epoch in range(15):\n",
    "    ## model.train\n",
    "    s2s.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    ## training bathces in gpu\n",
    "#we have put our data into batches\n",
    "    for i, batch in enumerate(train_loader):\n",
    "#Loadinng each batch and its respective label.\n",
    "        data = batch['data'].permute(2, 0, 1).cuda()\n",
    "        label = batch['label'].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "#data is been sent to s2s architecture\n",
    "        output = s2s(data)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    ## evaluating the trained model on validation set\n",
    "    s2s.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "\n",
    "            data = batch['data'].permute(2, 0, 1).cuda()\n",
    "            label = batch['label'].cuda()\n",
    "            output = s2s(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print('Epoch : {} train_loss : {} val_loss : {}'.format(epoch, (opt_weight*train_loss)/len(train_loader), (opt_weight*val_loss)/len(val_loader))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3m0IcvM1Wvw",
    "outputId": "8cb58e80-fd9f-489b-efcd-228b3b0ee403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.85\n",
      "Precision: 0.889\n",
      "Recall: 0.887\n",
      "F1score: 0.835\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "### Calculating the metrics\n",
    "fin_targets = []\n",
    "fin_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(train_loader):\n",
    "\n",
    "        data = batch['data'].permute(2, 0, 1).cuda()\n",
    "        label = batch['label']\n",
    "        output = s2s(data)\n",
    "        fin_targets.append(np.asarray(label.numpy(),dtype=np.int))\n",
    "        fin_outputs.append(np.asarray((output.cpu().detach().numpy()>0.5), dtype=np.int))\n",
    "\n",
    "acc,precision,recall,f1score=classification_report(fin_outputs,fin_targets,best_class_weights)\n",
    "print('Accuracy : {}'.format(acc))\n",
    "print('Precision: {}'.format(precision))\n",
    "print('Recall: {}'.format(recall))\n",
    "print('F1score: {}'.format(f1score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_selfattention_explaination.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
