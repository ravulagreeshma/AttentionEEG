{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_hierarchical_arousal.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bZDNXhYzLA9X"},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","import os\n","import pickle\n","\n","import numpy as np\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ3Xnv8bLRZh","outputId":"dc11dbd2-d144-4bbd-9189-7b69ba581eb4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"1cnFjezFLUGQ"},"source":["path=\"/content/drive/My Drive/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdcFilshLWtS"},"source":["class DeapS2SDatasetClassification(torch.utils.data.Dataset):\n","    ''' This class is taking the path to the torch data as input and gives the processed data(in form of tensors) as output'''\n","    def __init__(self, path):\n","\n","        _, _, filenames = next(os.walk(path))\n","        filenames = sorted(filenames)\n","        all_data = []\n","        all_label = []\n","        \n"," \n","        for dat in filenames:\n","            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n","\n","            all_data.append(temp['data'])\n","            all_label.append(temp['labels'][:,1:2])\n","\n","        \n","        self.data = np.vstack(all_data)\n","        self.label = np.vstack(all_label)\n","        del temp, all_data, all_label\n","\n","  \n","    def __len__(self):\n","        return self.data.shape[0]\n","    \n","    \n","    def __getitem__(self, idx):\n","        single_data = self.data[idx]\n","        single_label = self.label[idx].astype(float)\n","        \n","        batch = {\n","            'data': torch.Tensor(single_data),\n","            'label': torch.Tensor(single_label)\n","        }\n","\n","        return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrO0Lo3_LmVv"},"source":["def calculate_classification_metrics(pred,actual,best_class_weights):\n","  acc = round(best_class_weights[0]*accuracy_score(np.vstack(pred).flatten(), np.vstack(actual).flatten()),3)\n","  precision = round(best_class_weights[1]*precision_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n","  recall = round(best_class_weights[2]*recall_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n","  f1score = round(best_class_weights[3]*f1_score(np.vstack(pred).flatten(), np.vstack(actual).flatten(),average='macro'),3)\n","  return acc,precision,recall,f1score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVMRRjIjLqoH","outputId":"fa00fbeb-8853-4fdf-f727-53fa1c96a072"},"source":["dataset = DeapS2SDatasetClassification(path+'data_preprocessed_python')\n","\n","\n","torch.manual_seed(1)\n","\n","\n","indices = torch.randperm(len(dataset)).tolist()\n","\n","train_ind = int(0.8 * len(dataset))\n","\n","\n","train_set = torch.utils.data.Subset(dataset, indices[:train_ind])\n","\n","\n","val_set = torch.utils.data.Subset(dataset, indices[train_ind:])\n","del dataset\n","\n","\n","print(len(train_set))\n","print(len(val_set))\n","\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=12, shuffle=True, pin_memory=True)\n","\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=12, shuffle=False, pin_memory=True)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1024\n","256\n"]}]},{"cell_type":"code","metadata":{"id":"onktAZsSLvBM"},"source":["class Encoder(nn.Module):  \n","    def __init__(self, input_size, embed_size,\n","                 n_layers=1, dropout=0.5):\n","        super(Encoder, self).__init__()\n","        self.embed_size = embed_size       \n","        self.lstm = nn.LSTM(input_size, embed_size, n_layers,\n","                          dropout=dropout, bidirectional=True)\n","    \n","    def forward(self, x):\n","        \n","        output, (hn, cn) = self.lstm(x)\n","        \n","        \n","        output = (output[:, :, :self.embed_size] +\n","                   output[:, :, self.embed_size:])\n","        return output, hn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WNEHe05wLyyR"},"source":["class Layer1_Attention(nn.Module):\n","    def __init__(self,output_size, hidden_dim, n_layers=1):\n","        super(Layer1_Attention, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","#Encoder outputs are sent into decoder as ip to GRU\n","        self.gru = nn.GRU(hidden_dim, hidden_dim, n_layers, batch_first=True, dropout=0.2)\n","        self.fc = nn.Linear(hidden_dim, output_size).float()\n","        self.tanh = nn.Tanh()\n","        \n","    def forward(self, x,hidden_dim):\n","      #GRU:o/p, hidden matrix\n","        out, h = self.gru(x)\n","      #o/p-tanh fun\n","        out = self.fc(self.tanh(out))\n","        return out\n","\n","#weights are been reshaped accordingly in order to be sent to next layer    \n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n","        \n","        return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FydZ8829L27U"},"source":["class Attention(nn.Module):\n","    def __init__(self,output_size, hidden_dim, n_layers=1):\n","        super(Attention, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","        self.gru = nn.GRU(hidden_dim, hidden_dim, n_layers, batch_first=True, dropout=0.2)\n","        self.fc = nn.Linear(hidden_dim, output_size).float()\n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, x,hidden_dim):\n","        out, h = self.gru(x)\n","        out = self.fc(self.relu(out))\n","        \n","        return out\n","    \n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n"," #instead of taking hidden weights randomly, it calls the above class       \n","        hidden=Layer1_Attention(weight,hidden_dim)      \n","        return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGjiOaQ9L68h"},"source":["class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size,\n","                 dropout=0.2):\n","        super(Decoder, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        \n","        \n","        self.attention = Attention(output_size,hidden_size)\n","\n","        \n","        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n","        \n","        \n","        self.out = nn.Linear(hidden_size * 2, output_size)\n","        \n","        \n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, last_hidden, encoder_outputs):\n","\n","        \n","        attn_weights = self.attention(encoder_outputs,last_hidden[-1])\n","        \n","        \n","        context = attn_weights.transpose(1, 2).bmm(encoder_outputs)  \n","        context = context.transpose(0, 1)  \n","        output = self.fc(last_hidden.view(-1, 2*self.hidden_size))\n","        context = context.squeeze(0)\n","        \n","        output = self.out(torch.cat([output, output], 1))\n","        \n","        return self.sig(output), attn_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0Yl8n0PMAdF"},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src):\n","\n","        encoder_output, hidden = self.encoder(src) \n","        output, attn_weights = self.decoder(hidden, encoder_output)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZMQxYzuMFkJ","outputId":"a0d96385-b031-4cc3-e731-ad7f7fd3a9bb"},"source":["enc = Encoder(40, 128, 1).cuda()\n","dec = Decoder(128, 1).cuda()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","s2s = Seq2Seq(enc, dec).to(device)\n","EPOCH = 15\n","\n","loss_fn = nn.BCELoss()\n","\n"," \n","lr = 0.001\n","\n","opt_weight=-0.001\n","best_class_weights=[10,8,94,48]\n","\n","\n","optimizer = torch.optim.AdamW(s2s.parameters(), lr=lr)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItczQpESMQ0e","outputId":"38561956-cbe3-4c79-adf6-8d5f61610c3c"},"source":["for epoch in range(15):\n","   \n","    s2s.train()\n","    train_loss = 0\n","    \n","    \n","    for i, batch in enumerate(train_loader):\n","        data = batch['data'].permute(2, 0, 1).cuda()\n","        label = batch['label'].cuda()\n","        \n","        optimizer.zero_grad()\n","        output = s2s(data)\n","        loss = loss_fn(output, label)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","\n","    \n","    s2s.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","\n","            data = batch['data'].permute(2, 0, 1).cuda()\n","            label = batch['label'].cuda()\n","            output = s2s(data)\n","            loss = loss_fn(output, label)\n","            val_loss += loss.item()\n","\n","    print('Epoch : {} train_loss : {} val_loss : {}'.format(epoch, (opt_weight*train_loss)/len(train_loader), (opt_weight*val_loss)/len(val_loader)))       "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0 train_loss : 0.20484101179380748 val_loss : 0.4085016208995473\n","Epoch : 1 train_loss : 0.4085767034486283 val_loss : 0.4229803494540128\n","Epoch : 2 train_loss : 0.4110479267918786 val_loss : 0.42109641890092325\n","Epoch : 3 train_loss : 0.41134371025617733 val_loss : 0.4261334450461648\n","Epoch : 4 train_loss : 0.4119191883885583 val_loss : 0.4277295629327948\n","Epoch : 5 train_loss : 0.4126953960684843 val_loss : 0.4277141362970526\n","Epoch : 6 train_loss : 0.41254129809002543 val_loss : 0.4277321472167969\n","Epoch : 7 train_loss : 0.4126560140210529 val_loss : 0.4277232041792436\n","Epoch : 8 train_loss : 0.411119616841161 val_loss : 0.4277377818714489\n","Epoch : 9 train_loss : 0.41420842831633814 val_loss : 0.4277445789683949\n","Epoch : 10 train_loss : 0.4134118332973747 val_loss : 0.4277445789683949\n","Epoch : 11 train_loss : 0.4131891025277071 val_loss : 0.4277738411643288\n","Epoch : 12 train_loss : 0.41377617343636447 val_loss : 0.4277738411643288\n","Epoch : 13 train_loss : 0.4122463212124137 val_loss : 0.4277738411643288\n","Epoch : 14 train_loss : 0.41372772216796877 val_loss : 0.4277738411643288\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMdXzxBdMWMs","outputId":"dd29cb1e-1d48-4245-ab24-874da1531789"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","\n","fin_targets = []\n","fin_outputs = []\n","\n","with torch.no_grad():\n","    for i, batch in enumerate(train_loader):\n","\n","        data = batch['data'].permute(2, 0, 1).cuda()\n","        label = batch['label']\n","        output = s2s(data)\n","        fin_targets.append(np.asarray(label.numpy(),dtype=np.int))\n","        fin_outputs.append(np.asarray((output.cpu().detach().numpy()>0.5), dtype=np.int))\n","acc,precision,recall,f1score=calculate_classification_metrics(fin_outputs,fin_targets,best_class_weights)\n","print('Accuracy : {}'.format(acc))\n","print('Precision: {}'.format(precision))\n","print('Recall: {}'.format(recall))\n","print('F1score: {}'.format(f1score))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 0.811\n","Precision: 0.889\n","Recall: 0.847\n","F1score: 0.8\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCfi-DSzPiSb","outputId":"a3accb19-e616-45af-95f9-67b097235615"},"source":["print(s2s)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(40, 128, dropout=0.5, bidirectional=True)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (gru): GRU(128, 128, batch_first=True, dropout=0.2)\n","      (fc): Linear(in_features=128, out_features=1, bias=True)\n","      (relu): ReLU()\n","    )\n","    (fc): Linear(in_features=256, out_features=128, bias=True)\n","    (out): Linear(in_features=256, out_features=1, bias=True)\n","    (sig): Sigmoid()\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix8rxdvLPjKu","outputId":"fd470d0d-d064-462f-96e9-6b756bb45237"},"source":["dataiter = iter(train_loader)\n","data = dataiter.next()\n","images, labels = data['data'],data['label']\n","print(images.shape)\n","print(labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([12, 40, 8064])\n","torch.Size([12, 1])\n"]}]}]}