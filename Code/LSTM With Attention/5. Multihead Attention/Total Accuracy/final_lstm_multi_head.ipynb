{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_lstm_multi_head.ipynb","provenance":[{"file_id":"1Ib7aMLmBOGldl31_jnjYEGUZyJb_4Kvy","timestamp":1637927222009},{"file_id":"1WjqRDK26-kdHq3f5-i1PizXcJKaxYERU","timestamp":1637918663632}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2ZgPK-Vujbss"},"source":["Final_multi_head_attention\n"," : batch_size=1, number of heads =8, , hidden dim=256, RMS prop, regularisation, cross entropy"]},{"cell_type":"code","metadata":{"id":"yqgSZtx5SJvc"},"source":["import torch\n","import torch.nn as nn\n","import os\n","import pickle\n","import numpy as np\n","import math\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jkmt1WcWw8v"},"source":["import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8qrnjTNzJfR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26xdB6iqW0G2","executionInfo":{"status":"ok","timestamp":1637928547228,"user_tz":-420,"elapsed":5,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"94fff537-5e0a-4a83-f867-3e01ff565924"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"a422e1TKXBDg"},"source":["path='/content/drive/My Drive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NzroCt6XD4R"},"source":["class DeapS2SDatasetClassification(torch.utils.data.Dataset):\n","    \n","    def __init__(self, path):\n","\n","        _, _, filenames = next(os.walk(path))\n","        filenames = sorted(filenames)\n","        all_data = []\n","        all_label = []\n","        for dat in filenames:\n","            temp = pickle.load(open(os.path.join(path,dat), 'rb'), encoding='latin1')\n","            all_data.append(temp['data'])\n","            all_label.append(temp['labels'][:,:2])\n","\n","        self.data = np.vstack(all_data)\n","        self.label = np.vstack(all_label)\n","        del temp, all_data, all_label\n","\n","    def __len__(self):\n","        return self.data.shape[0]\n","\n","   \n","    def __getitem__(self, idx):\n","        single_data = self.data[idx]\n","        single_label = (self.label[idx] > 5).astype(float)\n","        \n","        batch = {\n","            'data': torch.Tensor(single_data),\n","            'label': torch.Tensor(single_label)\n","        }\n","\n","        return batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYAZvdDBXKVw","executionInfo":{"status":"ok","timestamp":1637928605195,"user_tz":-420,"elapsed":43059,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"5444d255-cc43-4137-bcc1-05df0045e6fe"},"source":["dataset = DeapS2SDatasetClassification(path+'data_preprocessed_python')\n","\n","torch.manual_seed(1)\n","indices = torch.randperm(len(dataset)).tolist()\n","train_ind = int(0.7 * len(dataset))\n","train_set = torch.utils.data.Subset(dataset, indices[:train_ind])\n","val_set = torch.utils.data.Subset(dataset, indices[train_ind:])\n","del dataset\n","\n","print(len(train_set))\n","print(len(val_set))\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, pin_memory=True)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=False, pin_memory=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["896\n","384\n"]}]},{"cell_type":"code","metadata":{"id":"WZkJ89bQXfvo"},"source":["#model hyperparameters\n","input_dim = 40\n","hidden_dim = 256\n","\n","output_dim = 2\n","\n","num_layers = 1\n","bidirectional = True\n","dropout = 0.5\n","\n","\n","batch_size = 1\n","num_epochs = 15\n","lr=0.0001\n","\n","\n","n_heads = 8\n","head_dimensions = (hidden_dim * 2) // n_heads "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJaaeZnVX0sa"},"source":["def calcuate_accuracy(val_loader,model,data):\n","  fin_targets = []\n","  fin_outputs = []\n","  with torch.no_grad():\n","      for i, batch in enumerate(val_loader):\n","\n","          data = batch['data'].permute(2, 0, 1).cuda()\n","          label = batch['label']\n","          output = model(data)\n","          fin_targets.append(label.numpy())\n","          fin_outputs.append(np.asarray((output.cpu().detach().numpy()>0.5)[0].reshape((1,2)), dtype=np.int))\n","          \n","          # print(len(fin_outputs),len(fin_targets))\n","  # print(len(fin_outputs),len(fin_targets))\n","  # print(fin_outputs[0].shape,fin_targets[0].shape)\n","\n","\n","  acc = round((accuracy_score(np.vstack(fin_outputs).flatten(), np.vstack(fin_targets).flatten())),3)\n","  precision = round(precision_score(np.vstack(fin_outputs).flatten(), np.vstack(fin_targets).flatten()),3)\n","  recall = round(recall_score(np.vstack(fin_outputs).flatten(), np.vstack(fin_targets).flatten()),3)\n","  f1score = round(f1_score(np.vstack(fin_outputs).flatten(), np.vstack(fin_targets).flatten()),3)\n","\n","  print('Accuracy : {}'.format(acc))\n","  print('Precision: {}'.format(precision))\n","  print('Recall: {}'.format(recall))\n","  print('F1score: {}'.format(f1score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9Z9b_jDX52n"},"source":["class LSTM(nn.Module):\n","    def __init__(self, len_reduction='mean'):\n","        super().__init__()\n","        \n","        \n","        self.lstm = nn.LSTM(input_dim, \n","                           hidden_dim, \n","                           num_layers=num_layers, \n","                           bidirectional=bidirectional, \n","                           dropout=dropout,\n","                           batch_first=True)\n","        \n","        \n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        self.softmax       = nn.Softmax(dim=1)\n","        self.len_reduction = len_reduction\n","        self.lin_Q = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.lin_K = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.lin_V = nn.Linear(hidden_dim * 2, hidden_dim * 2)\n","        self.layer_norm = nn.LayerNorm(hidden_dim * 2)\n","        \n","    # lstm_output : [batch_size, seq len, n_hidden * num_directions(=2)]\n","    def multi_head_Attention(self, lstm_output):           \n","        residual, batch_size = lstm_output, lstm_output.size(0) \n","        q = self.lin_Q(torch.clone(lstm_output))\n","        k = self.lin_K(torch.clone(lstm_output))\n","        v = self.lin_V(torch.clone(lstm_output))\n","       \n","        \n","        #split into heads\n","        q = q.view(batch_size, -1, n_heads, head_dimensions).transpose(1,2)  # q: [batch_size x n_heads x seq_len x d_k]\n","        k = k.view(batch_size, -1, n_heads, head_dimensions).transpose(1,2)  # k: [batch_size x n_heads x seq_len x d_k]\n","        v = v.view(batch_size, -1, n_heads, head_dimensions).transpose(1,2)  # v: [batch_size x n_heads x seq_len x d_k]\n","        \n","        \n","        # dot production attention\n","        attn_w = torch.matmul(q, k.transpose(-1, -2)) / np.sqrt(head_dimensions) # [batch_size x n_heads x seq_len x seq_len]\n","                \n","     \n","        sfmx_attn_w = self.softmax(attn_w)\n","        context = torch.matmul(sfmx_attn_w, v) # [batch_size x n_heads x seq_len x d_k]\n","        \n","        # concatenate heads\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * head_dimensions) \n","        \n","        # doing skip connection\n","\n","        context = self.layer_norm(residual + context)\n","\n","        if self.len_reduction == \"mean\":\n","            return torch.mean(context, dim=1)\n","        elif self.len_reduction == \"sum\":\n","            return torch.sum(context, dim=1)\n","        elif self.len_reduction == \"last\":\n","            return context[:, -1, :]\n","        \n","    def forward(self, x):\n","       \n","        \n","        \n","        output, (hn, cn) = self.lstm(x)  \n","        \n","\n","        \n","                \n","        attn_output = self.multi_head_Attention(output)        \n","        \n","        \n","        return self.softmax(self.fc(attn_output))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgs5vh_fYDWJ"},"source":["def initialize(model):\n","    if isinstance(model, nn.Linear):\n","        nn.init.xavier_normal_(model.weight)\n","        nn.init.zeros_(model.bias)\n","    elif isinstance(model, nn.RNN):\n","        for name, param in model.named_parameters():\n","            if 'bias' in name:\n","                nn.init.zeros_(param)\n","            elif 'weight' in name:\n","                nn.init.orthogonal_(param) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1B22sjyYHOy","executionInfo":{"status":"ok","timestamp":1637928668741,"user_tz":-420,"elapsed":10403,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"f2cd45d8-e382-40f9-fa1c-bd141e2fb2a6"},"source":["weight = torch.empty(2, 2)\n","nn.init.orthogonal_(weight)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LSTM().to(device)\n","model.apply(initialize)\n","loss_fn = nn.BCELoss()\n","optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, weight_decay=1e-5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ruxVFO8YN8N","executionInfo":{"status":"ok","timestamp":1637938524231,"user_tz":-420,"elapsed":9851746,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"eb782ddb-4601-4f64-a89c-f78d728d9c85"},"source":["for epoch in range(15):\n","    model.train()\n","    train_loss = 0\n","\n","    for i, batch in enumerate(train_loader):\n","        data = batch['data'].permute(0,2,1).to(device)\n","        label = batch['label'].to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(data)\n","        \n","        \n","        loss = loss_fn(output, label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","\n","            data = batch['data'].permute(0,2,1).to(device)\n","            label = batch['label'].to(device)\n","            output = model(data)\n","            \n","            loss = loss_fn(output, label)\n","            val_loss += loss.item()\n","\n","    print('Epoch : {} train_loss : {} val_loss : {}'.format(epoch, train_loss/len(train_loader), val_loss/len(val_loader)))  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 0 train_loss : 0.8951234519481659 val_loss : 0.8411302839716276\n","Epoch : 1 train_loss : 0.8240546872174102 val_loss : 0.7939899898289392\n","Epoch : 2 train_loss : 0.7802981531047928 val_loss : 0.7854116858604053\n","Epoch : 3 train_loss : 0.7563631638684976 val_loss : 0.7985597400305172\n","Epoch : 4 train_loss : 0.7469965152309409 val_loss : 0.8004039193037897\n","Epoch : 5 train_loss : 0.7351229381082314 val_loss : 0.7917842714426419\n","Epoch : 6 train_loss : 0.7231129079258868 val_loss : 0.7920262437934676\n","Epoch : 7 train_loss : 0.7134338446027998 val_loss : 0.7939569146838039\n","Epoch : 8 train_loss : 0.7031935340325747 val_loss : 0.7989229888189584\n","Epoch : 9 train_loss : 0.6998732374714953 val_loss : 0.8060413359198719\n","Epoch : 10 train_loss : 0.6915650189122451 val_loss : 0.8107185553138455\n","Epoch : 11 train_loss : 0.684821803388851 val_loss : 0.8073807554319501\n","Epoch : 12 train_loss : 0.6763399712342236 val_loss : 0.8177017191580186\n","Epoch : 13 train_loss : 0.6745381571818143 val_loss : 0.796395643070961\n","Epoch : 14 train_loss : 0.6686840303175684 val_loss : 0.8006649949432662\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJKEoaSAjT8A","executionInfo":{"status":"ok","timestamp":1637938570147,"user_tz":-420,"elapsed":3925,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"620c0f1d-5d1c-4bad-94be-c158dcbe663f"},"source":["calcuate_accuracy(val_loader,model,data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 0.53\n","Precision: 0.527\n","Recall: 0.591\n","F1score: 0.557\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVM5NwMVzNJX","executionInfo":{"status":"ok","timestamp":1637939480448,"user_tz":-420,"elapsed":786,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"0fc3fade-8be4-4086-e5a1-7fac21a69b8b"},"source":["print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM(\n","  (lstm): LSTM(40, 256, batch_first=True, dropout=0.5, bidirectional=True)\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n","  (lin_Q): Linear(in_features=512, out_features=512, bias=True)\n","  (lin_K): Linear(in_features=512, out_features=512, bias=True)\n","  (lin_V): Linear(in_features=512, out_features=512, bias=True)\n","  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTwcKvM0zc4Q","executionInfo":{"status":"ok","timestamp":1637939561912,"user_tz":-420,"elapsed":493,"user":{"displayName":"Pranisaa Charnparttaravanit","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqKYEQa50zsrJinsZpTK3CiHtl-XM01aOxNMo6=s64","userId":"18284836492986785965"}},"outputId":"ea82fc85-79a3-41ee-fcb3-13a219d15084"},"source":["dataiter = iter(train_loader)\n","data = dataiter.next()\n","images, labels = data['data'],data['label']\n","print(images.shape)\n","print(labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 40, 8064])\n","torch.Size([1, 2])\n"]}]}]}